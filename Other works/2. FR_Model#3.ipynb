{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amritesh-gaurav/Face-Detection/blob/main/Recognize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nABM-RHuzYri"
      },
      "source": [
        "### Part 1: Initialize and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVFE6IKYtLzs"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import scipy.misc\n",
        "import imageio\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMxDiXLFxzxz"
      },
      "outputs": [],
      "source": [
        "# Get Face Detector from dlib\n",
        "# This allows us to detect faces in images\n",
        "face_detector = dlib.get_frontal_face_detector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gqG6NC-y5lj"
      },
      "outputs": [],
      "source": [
        "# Get Pose Predictor from dlib\n",
        "# This allows us to detect landmark points in faces and understand the pose/angle of the face\n",
        "shape_predictor = dlib.shape_predictor('/content/shape_predictor_68_face_landmarks.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jITrwqCy5pS"
      },
      "outputs": [],
      "source": [
        "# Get the face recognition model\n",
        "# This is what gives us the face encodings (numbers that identify the face of a particular person)\n",
        "face_recognition_model = dlib.face_recognition_model_v1('/content/dlib_face_recognition_resnet_model_v1.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfeNX5TQy5sb"
      },
      "outputs": [],
      "source": [
        "# This is the tolerance for face comparisons\n",
        "# The lower the number - the stricter the comparison\n",
        "# To avoid false matches, use lower value\n",
        "# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n",
        "# 0.5-0.6 works well\n",
        "TOLERANCE = 0.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya4eydQBzh6j"
      },
      "source": [
        "### Part 2: Get face encodings from an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21lWiWiRy5xk"
      },
      "outputs": [],
      "source": [
        "# This function will take an image and return its face encodings using the neural network\n",
        "def get_face_encodings(path_to_image):\n",
        "    # Load image using scipy\n",
        "    image = imageio.imread(path_to_image)\n",
        "    # Detect faces using the face detector\n",
        "    detected_faces = face_detector(image, 1)\n",
        "    # Get pose/landmarks of those faces\n",
        "    # Will be used as an input to the function that computes face encodings\n",
        "    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "    shapes_faces = [shape_predictor(image, face) for face in detected_faces]\n",
        "    # For every face detected, compute the face encodings\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cUZk_oDzx_b"
      },
      "source": [
        "### Part 3a: Compare faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCSs5UWxy5zr"
      },
      "outputs": [],
      "source": [
        "# This function takes a list of known faces\n",
        "def compare_face_encodings(known_faces, face):\n",
        "    # Finds the difference between each known face and the given face (that we are comparing)\n",
        "    # Calculate norm for the differences with each known face\n",
        "    # Return an array with True/Face values based on whether or not a known face matched with the given face\n",
        "    # A match occurs when the (norm) difference between a known face and the given face is less than or equal to the TOLERANCE value\n",
        "    return (np.linalg.norm(known_faces - face, axis=1) <= TOLERANCE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqSV0lPz3hS"
      },
      "source": [
        "### Part 3b: Find match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aKW773Vy51r"
      },
      "outputs": [],
      "source": [
        "# This function returns the name of the person whose image matches with the given face (or 'Not Found')\n",
        "# known_faces is a list of face encodings\n",
        "# names is a list of the names of people (in the same order as the face encodings - to match the name with an encoding)\n",
        "# face is the face we are looking for\n",
        "def find_match(known_faces, names, face):\n",
        "    # Call compare_face_encodings to get a list of True/False values indicating whether or not there's a match\n",
        "    matches = compare_face_encodings(known_faces, face)\n",
        "    # Return the name of the first match\n",
        "    count = 0\n",
        "    for match in matches:\n",
        "        if match:\n",
        "            return names[count]\n",
        "        count += 1\n",
        "    # Return not found if no match found\n",
        "    return 'Not Found'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlPkqNaEz_pa"
      },
      "source": [
        "### Part 4a: Getting face encodings for all faces in the images folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_qa2NH2y53z"
      },
      "outputs": [],
      "source": [
        "# Get path to all the known images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/images/'))\n",
        "# Sort in alphabetical order\n",
        "image_filenames = sorted(image_filenames)\n",
        "# Get full paths to images\n",
        "paths_to_images = ['/content/images/' + x for x in image_filenames]\n",
        "# List of face encodings we have\n",
        "face_encodings = []\n",
        "# Loop over images to get the encoding one by one\n",
        "for path_to_image in paths_to_images:\n",
        "    # Get face encodings from the image\n",
        "    face_encodings_in_image = get_face_encodings(path_to_image)\n",
        "    # Make sure there's exactly one face in the image\n",
        "    if len(face_encodings_in_image) != 1:\n",
        "        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "        exit()\n",
        "    # Append the face encoding found in that image to the list of face encodings we have\n",
        "    face_encodings.append(get_face_encodings(path_to_image)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qu6oJRE0I9r"
      },
      "source": [
        "### Part 4b: Matching each image in test folder with the known faces (one by one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n50hM5tU0Twx",
        "outputId": "9a6bda70-6c8d-4190-b237-1a860334f61f"
      },
      "outputs": [],
      "source": [
        "# Get path to all the test images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "test_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/test/'))\n",
        "# Get full paths to test images\n",
        "paths_to_test_images = ['/content/test/' + x for x in test_filenames]\n",
        "# Get list of names of people by eliminating the .JPG extension from image filenames\n",
        "names = [x[:-4] for x in image_filenames]\n",
        "# Iterate over test images to find match one by one\n",
        "for path_to_image in paths_to_test_images:\n",
        "    # Get face encodings from the test image\n",
        "    face_encodings_in_image = get_face_encodings(path_to_image)\n",
        "    # Make sure there's exactly one face in the image\n",
        "    if len(face_encodings_in_image) != 1:\n",
        "        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "        exit()\n",
        "    # Find match for the face encoding found in this test image\n",
        "    match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
        "    # Print the path of test image and the corresponding match\n",
        "    print(path_to_image, match)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOe8a5h11X//PNe5lMivefy",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Recognize.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
